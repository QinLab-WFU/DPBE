{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stochman import nnj\n",
    "import numpy as np\n",
    "from jax import numpy as jnp\n",
    "from jax import vjp\n",
    "from jax import lax # for convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_size = 1\n",
    "_input_size = 3\n",
    "_hidden_size = 48\n",
    "_hidden_c_in, _hidden_c_out = 3, 2\n",
    "_hidden_h, _hidden_w = 4, 4\n",
    "assert _hidden_size == _hidden_c_in * _hidden_h * _hidden_w\n",
    "_kernel_size, _padding = 3,1\n",
    "assert _kernel_size == 2*_padding + 1\n",
    "_output_size = 7\n",
    "\n",
    "\n",
    "x1 = torch.randn(_batch_size, _input_size)\n",
    "x2 = torch.randn(_batch_size, _input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nnj.Linear(_input_size, _hidden_size),\n",
    "          nnj.Tanh(),\n",
    "          nnj.Reshape(_hidden_c_in, _hidden_h, _hidden_w),\n",
    "          nnj.Conv2d(_hidden_c_in, _hidden_c_out, _kernel_size, stride=1, padding=_padding),\n",
    "          nnj.Flatten(),\n",
    "          nnj.Tanh(),\n",
    "          nnj.Linear(_hidden_c_out * _hidden_h * _hidden_w, _output_size),\n",
    "          nnj.L2Norm()\n",
    "          ]\n",
    "                        \n",
    "stoch_model = nnj.Sequential(*layers,\n",
    "                            add_hooks = True\n",
    ")\n",
    "\n",
    "### test single input ###\n",
    "y1 = stoch_model(x1)\n",
    "y2 = stoch_model(x2)\n",
    "\n",
    "matrixes = tuple(torch.ones(_batch_size, _output_size) for _ in range(3))\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'input', from_diag = True, to_diag = True)\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'input', from_diag = True, to_diag = False)\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'weight', from_diag = True, to_diag = True)\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'weight', from_diag = True, to_diag = False)\n",
    "\n",
    "matrixes = tuple(torch.ones(_batch_size, _output_size, _output_size) for _ in range(3))\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'input', from_diag = False, to_diag = True)\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'input', from_diag = False, to_diag = False)\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'weight', from_diag = False, to_diag = True)\n",
    "GGN = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt = 'weight', from_diag = False, to_diag = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 3]),\n",
       " torch.Size([1, 48]),\n",
       " torch.Size([1, 48]),\n",
       " torch.Size([1, 3, 4, 4]),\n",
       " torch.Size([1, 2, 4, 4]),\n",
       " torch.Size([1, 32]),\n",
       " torch.Size([1, 32]),\n",
       " torch.Size([1, 7]),\n",
       " torch.Size([1, 7])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fm.shape for fm in stoch_model.feature_maps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights in stoch model:\n",
      "\tlinear 1 - W\n",
      "\t (48, 3)\n",
      "\tlinear 1 - b\n",
      "\t (48,)\n",
      "\tconv - K\n",
      "\t (2, 3, 3, 3)\n",
      "\tconv - b\n",
      "\t (2,)\n",
      "\tlinear 2 - W\n",
      "\t (7, 32)\n",
      "\tlinear 2 - b\n",
      "\t (7,)\n",
      "n weights per layer 192 56 231\n",
      "n weights total 479\n"
     ]
    }
   ],
   "source": [
    "first_linear_layer_index = 0\n",
    "conv_layer_index = 3\n",
    "second_linear_layer_index = 6\n",
    "\n",
    "print('Weights in stoch model:')\n",
    "\n",
    "print('\\tlinear 1 - W\\n\\t',stoch_model._modules_list[first_linear_layer_index].weight.detach().numpy().shape)\n",
    "print('\\tlinear 1 - b\\n\\t',stoch_model._modules_list[first_linear_layer_index].bias.detach().numpy().shape)\n",
    "\n",
    "print('\\tconv - K\\n\\t',stoch_model._modules_list[conv_layer_index].weight.detach().numpy().shape)\n",
    "print('\\tconv - b\\n\\t',stoch_model._modules_list[conv_layer_index].bias.detach().numpy().shape)\n",
    "\n",
    "print('\\tlinear 2 - W\\n\\t',stoch_model._modules_list[second_linear_layer_index].weight.detach().numpy().shape)\n",
    "print('\\tlinear 2 - b\\n\\t',stoch_model._modules_list[second_linear_layer_index].bias.detach().numpy().shape)\n",
    "\n",
    "\n",
    "weights = []\n",
    "\n",
    "for row in stoch_model._modules_list[first_linear_layer_index].weight.detach().numpy():\n",
    "    weights = np.concatenate((weights, row))\n",
    "weights = np.concatenate((weights, stoch_model._modules_list[first_linear_layer_index].bias.detach().numpy()))\n",
    "first_linear_num_weights = len(weights)\n",
    "\n",
    "for c_out in range(_hidden_c_out):\n",
    "    for c_in in range(_hidden_c_in):\n",
    "        kernel = stoch_model._modules_list[conv_layer_index].weight.detach().numpy()[c_out,c_in]\n",
    "        for row in kernel:\n",
    "            weights = np.concatenate((weights, row))\n",
    "weights = np.concatenate((weights, stoch_model._modules_list[conv_layer_index].bias.detach().numpy()))\n",
    "conv_num_weights = len(weights) - first_linear_num_weights\n",
    "\n",
    "for row in stoch_model._modules_list[second_linear_layer_index].weight.detach().numpy():\n",
    "    weights = np.concatenate((weights, row))\n",
    "weights = np.concatenate((weights, stoch_model._modules_list[second_linear_layer_index].bias.detach().numpy()))\n",
    "second_linear_num_weights = len(weights) - first_linear_num_weights - conv_num_weights\n",
    "\n",
    "weights = jnp.array(weights)\n",
    "print('n weights per layer', first_linear_num_weights, conv_num_weights, second_linear_num_weights)\n",
    "print('n weights total', len(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an equivalent Neural network on Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tanh(x):\n",
    "    return jnp.tanh(x)\n",
    "\n",
    "def L2Norm(x):\n",
    "    x = x.T / (jnp.linalg.norm(x, ord=2, axis=1) + 1e-6)\n",
    "    return x.T\n",
    "\n",
    "def LinearLayer(w, b, x, print_weights=False):\n",
    "    w = w.reshape(len(b), -1)\n",
    "    out = jnp.dot(x, w.T) + b\n",
    "    if print_weights:\n",
    "        print('\\twi\\n\\t',w)\n",
    "        print('\\tbi\\n\\t',b)\n",
    "    return out\n",
    "    \n",
    "def ConvLayer(k, b, x, print_weights=False):\n",
    "    k = k.reshape(_hidden_c_out, _hidden_c_in, _kernel_size, _kernel_size)\n",
    "    out = lax.conv(x,\n",
    "                   k,\n",
    "                   (1,1),\n",
    "                   'SAME')\n",
    "    bias = jnp.einsum(\"c,bchw->bchw\", b, jnp.ones_like(out))\n",
    "    out = out + bias\n",
    "    if print_weights:\n",
    "        print('\\tki\\n\\t',k)\n",
    "        print('\\tbi\\n\\t',b)\n",
    "    return out\n",
    "\n",
    "def Flatten(x):\n",
    "    return x.reshape(_batch_size, -1)\n",
    "\n",
    "def Reshape(x):\n",
    "    return x.reshape(_batch_size, _hidden_c_in, _hidden_h, _hidden_w)\n",
    "\n",
    "def jax_model(weights, x, print_weights=False, return_feature_maps=False):\n",
    "    # split the weights array\n",
    "    linear1_weights = weights[ : first_linear_num_weights]\n",
    "    w1 = linear1_weights[ : _input_size*_hidden_size]\n",
    "    b1 = linear1_weights[_input_size*_hidden_size : ]\n",
    "    LL1 = lambda x : LinearLayer(w1, b1, x, print_weights=print_weights)\n",
    "\n",
    "    conv_weights = weights[first_linear_num_weights : -second_linear_num_weights]\n",
    "    conv_k = conv_weights[ : -_hidden_c_out]\n",
    "    conv_b = conv_weights[-_hidden_c_out : ]\n",
    "    assert len(conv_k) == _hidden_c_in * _hidden_c_out * _kernel_size * _kernel_size and len(conv_b) == _hidden_c_out\n",
    "    CL = lambda x : ConvLayer(conv_k, conv_b, x, print_weights=print_weights)\n",
    "\n",
    "    linear2_weights = weights[-second_linear_num_weights : ]\n",
    "    w2 = linear2_weights[ : _hidden_c_out * _hidden_h * _hidden_w *_output_size]\n",
    "    b2 = linear2_weights[_hidden_c_out * _hidden_h * _hidden_w * _output_size : ]\n",
    "    LL2 = lambda x : LinearLayer(w2, b2, x, print_weights=print_weights)\n",
    "\n",
    "    fm = [x]\n",
    "    #for layer in [LL1, Tanh, Reshape, CL, Flatten, Tanh, LL2, L2Norm]:\n",
    "    for layer in [LL1, Tanh, Reshape, CL, Flatten, Tanh, LL2, L2Norm]:\n",
    "        x = layer(x)\n",
    "        fm.append(x)\n",
    "    if return_feature_maps:\n",
    "        return x, fm\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that outputs are the same for random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_inputs_amount = 100\n",
    "\n",
    "for _ in range(random_inputs_amount):\n",
    "    x = torch.randn(_batch_size, _input_size)\n",
    "    jax_x = jnp.array(x.numpy())\n",
    "\n",
    "    y = stoch_model(x)\n",
    "    jax_y,fm = jax_model(weights, jax_x, return_feature_maps=True)\n",
    "\n",
    "    #print([np.max(abs(fs.detach().numpy() - np.array(fj))) for fs,fj in zip(stoch_model.feature_maps, fm)])\n",
    "    assert max([np.max(abs(fs.detach().numpy() - np.array(fj))) for fs,fj in zip(stoch_model.feature_maps, fm)]) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correctness wrt weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that Vector-Jacobian products are the same for random inputs and random vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_inputs_amount = 10\n",
    "random_vectors_amount = 10\n",
    "\n",
    "for _ in range(random_inputs_amount):\n",
    "    x = torch.randn(_batch_size, _input_size)\n",
    "    jax_x = jnp.array(x.numpy())\n",
    "\n",
    "    jax_y_by_vjp, vjp_fun = vjp(lambda w: jax_model(w, jax_x), weights)\n",
    "\n",
    "    for _ in range(random_vectors_amount):\n",
    "        vector = torch.randn(_batch_size, _output_size)\n",
    "        jax_vector = jnp.array(vector.numpy())\n",
    "\n",
    "        #vector = torch.zeros((_batch_size, _output_size))\n",
    "        #vector[0,0] = 1\n",
    "        #jax_vector = jnp.zeros((_batch_size, _output_size))\n",
    "        #jax_vector = jax_vector.at[0,0].set(1)\n",
    "\n",
    "        jax_vj = vjp_fun(jax_vector)\n",
    "        stoch_vj = stoch_model._vjp(x, None, vector, wrt='weight')\n",
    "\n",
    "        difference = np.array(jax_vj) - stoch_vj.detach().numpy()\n",
    "        assert np.max(abs(difference)) < 1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix a pair of inputs (x1, x2) and compute the Jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian shape (7, 479)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(_batch_size, _input_size)\n",
    "x2 = torch.randn(_batch_size, _input_size)\n",
    "jax_x1 = jnp.array(x1.numpy())\n",
    "jax_x2 = jnp.array(x2.numpy())\n",
    "jax_y1_by_vjp, vjp_fun1 = vjp(lambda w: jax_model(w, jax_x1), weights)\n",
    "jax_y2_by_vjp, vjp_fun2 = vjp(lambda w: jax_model(w, jax_x2), weights)\n",
    "\n",
    "\n",
    "# define the identity matrix, for each batch element\n",
    "identity = []\n",
    "for i in range(_output_size):\n",
    "    e_i = jnp.zeros((_batch_size, _output_size))\n",
    "    for b in range(_batch_size):\n",
    "        e_i = e_i.at[b,i].set(1)\n",
    "    identity.append(e_i)\n",
    "\n",
    "J1_by_jax = []\n",
    "J2_by_jax = []\n",
    "for e_i in identity:\n",
    "    v1_i = vjp_fun1(e_i)\n",
    "    v2_i = vjp_fun2(e_i)\n",
    "    J1_by_jax.append(v1_i[0])\n",
    "    J2_by_jax.append(v2_i[0])\n",
    "\n",
    "J1_by_jax = np.array(J1_by_jax)\n",
    "J2_by_jax = np.array(J2_by_jax)\n",
    "assert J1_by_jax.shape == J2_by_jax.shape\n",
    "print('Jacobian shape', J1_by_jax.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a random matrix and backpropagate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check block diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 192) (192, 192)\n",
      "1.6763806e-07\n",
      "(56, 56) (56, 56)\n",
      "1.1086464e-05\n",
      "(231, 231) (231, 231)\n",
      "1.2278557e-05\n"
     ]
    }
   ],
   "source": [
    "matrixes = tuple(torch.randn(_batch_size, _output_size, _output_size) for _ in range(3))\n",
    "jax_matrixes = tuple(matrix.numpy() for matrix in matrixes)\n",
    " \n",
    "jmj_by_jax = np.einsum(\"ji,bjk,kq->biq\", J1_by_jax, jax_matrixes[0], J1_by_jax) \\\n",
    "                - np.einsum(\"ji,bjk,kq->biq\", J1_by_jax, jax_matrixes[1], J2_by_jax) \\\n",
    "                - np.einsum(\"ji,bjk,kq->bqi\", J1_by_jax, jax_matrixes[1], J2_by_jax) \\\n",
    "                + np.einsum(\"ji,bjk,kq->biq\", J2_by_jax, jax_matrixes[2], J2_by_jax)\n",
    "jmj_by_stoch = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt='weight')\n",
    "jmj_by_stoch = [matrixes[0] - matrixes[1] - matrixes[1].transpose(-2,-1) + matrixes[2] for matrixes in jmj_by_stoch]\n",
    "\n",
    "blocks_by_jax = [jmj_by_jax[0][:first_linear_num_weights, :first_linear_num_weights], \n",
    "                 jmj_by_jax[0][first_linear_num_weights: -second_linear_num_weights, first_linear_num_weights: -second_linear_num_weights], \n",
    "                 jmj_by_jax[0][-second_linear_num_weights:, -second_linear_num_weights:]\n",
    "]   \n",
    "\n",
    "for block in range(3):\n",
    "    print(blocks_by_jax[block].shape , jmj_by_stoch[block][0].detach().numpy().shape)\n",
    "    difference = blocks_by_jax[block] - jmj_by_stoch[block][0].detach().numpy()\n",
    "    print(np.max(abs(difference)))\n",
    "    assert np.max(abs(difference)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check exact diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479,) (479,)\n",
      "1.8000603e-05\n"
     ]
    }
   ],
   "source": [
    "matrixes = tuple(torch.randn(_batch_size, _output_size, _output_size) for _ in range(3))\n",
    "jax_matrixes = tuple(matrix.numpy() for matrix in matrixes)\n",
    " \n",
    "jmj_by_jax = np.einsum(\"ji,bjk,ki->bi\", J1_by_jax, jax_matrixes[0], J1_by_jax) \\\n",
    "                - 2 * np.einsum(\"ji,bjk,ki->bi\", J1_by_jax, jax_matrixes[1], J2_by_jax) \\\n",
    "                + np.einsum(\"ji,bjk,ki->bi\", J2_by_jax, jax_matrixes[2], J2_by_jax)\n",
    "jmj_by_stoch = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt='weight', to_diag=True)\n",
    "jmj_by_stoch = [matrixes[0] - 2 * matrixes[1] + matrixes[2] for matrixes in jmj_by_stoch]\n",
    "jmj_by_stoch = torch.cat(jmj_by_stoch, dim=1)\n",
    "\n",
    "print(jmj_by_jax[0].shape , jmj_by_stoch[0].detach().numpy().shape)\n",
    "difference = jmj_by_jax[0] - jmj_by_stoch[0].detach().numpy()\n",
    "print(np.max(abs(difference)))\n",
    "assert np.max(abs(difference)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correctness wrt the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that Vector-Jacobian products are the same for random inputs and random vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_inputs_amount = 10\n",
    "random_vectors_amount = 10\n",
    "\n",
    "for _ in range(random_inputs_amount):\n",
    "    x = torch.randn(_batch_size, _input_size)\n",
    "    jax_x = jnp.array(x.numpy())\n",
    "\n",
    "    jax_y_by_vjp, vjp_fun = vjp(lambda data: jax_model(weights, data), jax_x)\n",
    "\n",
    "    for _ in range(random_vectors_amount):\n",
    "        vector = torch.randn(_batch_size, _output_size)\n",
    "        jax_vector = jnp.array(vector.numpy())\n",
    "\n",
    "        #vector = torch.zeros((_batch_size, _output_size))\n",
    "        #vector[0,0] = 1\n",
    "        #jax_vector = jnp.zeros((_batch_size, _output_size))\n",
    "        #jax_vector = jax_vector.at[0,0].set(1)\n",
    "\n",
    "        jax_vj = vjp_fun(jax_vector)\n",
    "        stoch_vj = stoch_model._vjp(x, None, vector, wrt='input')\n",
    "\n",
    "        difference = np.array(jax_vj) - stoch_vj.detach().numpy()\n",
    "        assert np.max(abs(difference)) < 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix a pair of inputs (x1, x2) and compute the Jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian shape (7, 3)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(_batch_size, _input_size)\n",
    "x2 = torch.randn(_batch_size, _input_size)\n",
    "jax_x1 = jnp.array(x1.numpy())\n",
    "jax_x2 = jnp.array(x2.numpy())\n",
    "jax_y1_by_vjp, vjp_fun1 = vjp(lambda data: jax_model(weights, data), jax_x1)\n",
    "jax_y2_by_vjp, vjp_fun2 = vjp(lambda data: jax_model(weights, data), jax_x2)\n",
    "\n",
    "\n",
    "# define the identity matrix, for each batch element\n",
    "identity = []\n",
    "for i in range(_output_size):\n",
    "    e_i = jnp.zeros((_batch_size, _output_size))\n",
    "    for b in range(_batch_size):\n",
    "        e_i = e_i.at[b,i].set(1)\n",
    "    identity.append(e_i)\n",
    "\n",
    "J1_by_jax = []\n",
    "J2_by_jax = []\n",
    "for e_i in identity:\n",
    "    v1_i = vjp_fun1(e_i)\n",
    "    v2_i = vjp_fun2(e_i)\n",
    "    J1_by_jax.append(v1_i[0][0])\n",
    "    J2_by_jax.append(v2_i[0][0])\n",
    "\n",
    "J1_by_jax = np.array(J1_by_jax)\n",
    "J2_by_jax = np.array(J2_by_jax)\n",
    "assert J1_by_jax.shape == J2_by_jax.shape\n",
    "print('Jacobian shape', J1_by_jax.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a random matrix and backpropagate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check full case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3, 3)\n"
     ]
    }
   ],
   "source": [
    "matrixes = tuple(torch.randn(_batch_size, _output_size, _output_size) for _ in range(3))\n",
    "jax_matrixes = tuple(matrix.numpy() for matrix in matrixes)\n",
    " \n",
    "jmj_by_jax = np.einsum(\"ji,bjk,kq->biq\", J1_by_jax, jax_matrixes[0], J1_by_jax) \\\n",
    "                - np.einsum(\"ji,bjk,kq->biq\", J1_by_jax, jax_matrixes[1], J2_by_jax) \\\n",
    "                - np.einsum(\"ji,bjk,kq->bqi\", J1_by_jax, jax_matrixes[1], J2_by_jax) \\\n",
    "                + np.einsum(\"ji,bjk,kq->biq\", J2_by_jax, jax_matrixes[2], J2_by_jax)\n",
    "jmj_by_stoch = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt='input')\n",
    "jmj_by_stoch = jmj_by_stoch[0] - jmj_by_stoch[1] - jmj_by_stoch[1].transpose(-2,-1) + jmj_by_stoch[2]\n",
    "\n",
    "\n",
    "print(jmj_by_jax[0].shape , jmj_by_stoch[0].detach().numpy().shape)\n",
    "difference = jmj_by_jax - jmj_by_stoch.detach().numpy()\n",
    "assert np.max(abs(difference)) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check exact diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) (3,)\n"
     ]
    }
   ],
   "source": [
    "matrixes = tuple(torch.randn(_batch_size, _output_size, _output_size) for _ in range(3))\n",
    "jax_matrixes = tuple(matrix.numpy() for matrix in matrixes)\n",
    " \n",
    "jmj_by_jax = np.einsum(\"ji,bjk,ki->bi\", J1_by_jax, jax_matrixes[0], J1_by_jax) \\\n",
    "                - 2* np.einsum(\"ji,bjk,ki->bi\", J1_by_jax, jax_matrixes[1], J2_by_jax) \\\n",
    "                + np.einsum(\"ji,bjk,ki->bi\", J2_by_jax, jax_matrixes[2], J2_by_jax)\n",
    "jmj_by_stoch = stoch_model._jTmjp_batch2(x1, x2, None, None, matrixes, wrt='input', to_diag=True)\n",
    "jmj_by_stoch = jmj_by_stoch[0] - 2 * jmj_by_stoch[1] + jmj_by_stoch[2]\n",
    "\n",
    "\n",
    "print(jmj_by_jax[0].shape , jmj_by_stoch[0].detach().numpy().shape)\n",
    "difference = jmj_by_jax - jmj_by_stoch.detach().numpy()\n",
    "assert np.max(abs(difference)) < 1e-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('laplace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "477c387996a084153fd8ef9c4e5432322bdf7a5fc9ad0e2a4c514862f58a6dd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
